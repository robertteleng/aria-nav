# Recomendaciones de Optimizaci√≥n - FASE 4+

## üî¥ Problema Cr√≠tico Identificado: I/O Bloqueante

### S√≠ntomas
- Spikes peri√≥dicos de **350-400ms** cada ~50 frames (~2.5 segundos)
- FPS estable a 19.2 pero con drops puntuales a 14-15 FPS
- Patr√≥n consistente en toda la sesi√≥n

### Causa Ra√≠z
`TelemetryLogger` escribe **s√≠ncronamente a disco** en cada frame:
```python
def _write_jsonl(self, path: Path, data: Dict[str, Any]) -> None:
    with self._write_lock:
        with open(path, 'a', encoding='utf-8') as f:
            f.write(line + '\n')  # ‚Üê Bloqueante cuando OS hace flush
```

**Impacto:**
- 3+ escrituras por frame (performance.jsonl, detections.jsonl, audio_events.jsonl)
- Sistema operativo sincroniza buffers peri√≥dicamente ‚Üí 300-400ms stall
- Main thread bloqueado esperando I/O

---

## ‚úÖ Soluciones Recomendadas

### 1. **Telemetry As√≠ncrona con Background Thread** ‚≠ê PRIORITARIO

**Implementaci√≥n:**
```python
class AsyncTelemetryLogger(TelemetryLogger):
    def __init__(self, output_dir=None, flush_interval=1.0, buffer_size=100):
        super().__init__(output_dir)
        self._write_queue = queue.Queue(maxsize=1000)
        self._flush_thread = threading.Thread(target=self._flush_worker, daemon=True)
        self._flush_interval = flush_interval
        self._buffer_size = buffer_size
        self._flush_thread.start()
    
    def _write_jsonl(self, path: Path, data: Dict[str, Any]) -> None:
        """Queue write instead of blocking."""
        try:
            self._write_queue.put_nowait((path, data))
        except queue.Full:
            # Log error but don't block main thread
            pass
    
    def _flush_worker(self) -> None:
        """Background thread for batched disk writes."""
        buffers = {}  # path -> list of lines
        
        while True:
            try:
                # Collect writes with timeout
                path, data = self._write_queue.get(timeout=self._flush_interval)
                
                if path not in buffers:
                    buffers[path] = []
                
                line = json.dumps(data, ensure_ascii=True)
                buffers[path].append(line)
                
                # Flush if buffer full or timeout
                for file_path, lines in list(buffers.items()):
                    if len(lines) >= self._buffer_size:
                        self._flush_buffer(file_path, lines)
                        buffers[file_path] = []
                        
            except queue.Empty:
                # Timeout: flush all buffers
                for file_path, lines in list(buffers.items()):
                    if lines:
                        self._flush_buffer(file_path, lines)
                        buffers[file_path] = []
    
    def _flush_buffer(self, path: Path, lines: List[str]) -> None:
        """Batch write to disk."""
        try:
            with open(path, 'a', encoding='utf-8') as f:
                f.write('\n'.join(lines) + '\n')
        except Exception as e:
            print(f"[TELEMETRY ERROR] {e}")
```

**Beneficios:**
- Elimina bloqueos de I/O del thread principal
- Batch writes (100 l√≠neas de una vez) ‚Üí menos syscalls
- **Gana: ~300-400ms cada 2-3 segundos** = ~10-15% FPS improvement

**Riesgo:**
- P√©rdida de √∫ltimos frames si el programa crashea (mitigable con `atexit` flush)

---

### 2. **CUDA Streams para Overlapping** ‚úÖ YA IMPLEMENTADO

**Estado: COMPLETADO en central_worker.py**

```python
# Lines 83-85: Ya implementado
self.depth_stream = torch.cuda.Stream()
self.yolo_stream = torch.cuda.Stream()

# Lines 107-145: Ya en uso
with torch.cuda.stream(self.depth_stream):
    depth_tensor = self.depth_model.infer_image_gpu(frame_tensor, 384)

with torch.cuda.stream(self.yolo_stream):
    detections = self.yolo_processor.process_frame(frame, depth_map, depth_raw)

torch.cuda.synchronize()  # Wait for both
```

**Beneficios realizados:**
- ‚úÖ Depth (27ms) y YOLO (7ms) se ejecutan en paralelo
- ‚úÖ Overlap aprovecha idle time de GPU
- ‚úÖ Latencia total ~32ms en vez de ~34ms secuencial

**Nota:** Ya est√° funcionando en producci√≥n desde commit 8e4e69a (multiprocessing).

---

### 3. **Optimizar TTS** üîä BAJO

Alternativas a `pyttsx3`:

**Opci√≥n A: Generaci√≥n offline + playback**
```python
# Pre-generar WAV files al inicio
self.tts_cache = {
    "laptop": "audio/laptop.wav",
    "person": "audio/person.wav",
    ...
}

def speak_async(self, message):
    wav_file = self.tts_cache.get(message.lower())
    if wav_file:
        # sounddevice.play() es no-bloqueante
        sd.play(wav_data, samplerate=22050, blocking=False)
```

**Opci√≥n B: Festival/espeak directo (m√°s r√°pido)**
```bash
# Festival es ~50ms m√°s r√°pido que pyttsx3
festival --tts <<< "Laptop"
```

**Beneficios:**
- Elimina drops de 150ms durante TTS
- **Gana: ~100-150ms** cada vez que habla

---

### 4. **Frame Skipping Adaptativo** üìä BAJO

Saltar frames autom√°ticamente si latencia > threshold:

```python
if latency_ms > 60:  # Target: 50ms @ 20 FPS
    self.adaptive_skip = min(self.adaptive_skip + 1, 3)
else:
    self.adaptive_skip = max(self.adaptive_skip - 1, 0)
```

**Beneficios:**
- Mantiene FPS consistente bajo carga
- Evita acumulaci√≥n de latencia

---

## üìä Impacto Estimado

| Optimizaci√≥n | Ganancia FPS | Reducci√≥n Latencia | Prioridad | Estado |
|--------------|--------------|-------------------|-----------|--------|
| **Async Telemetry** | +2-3 FPS | -300ms spikes | ‚≠ê‚≠ê‚≠ê | ‚ùå Pendiente |
| **CUDA Streams** | ~2ms gained | Overlap depth+yolo | ‚úÖ | ‚úÖ HECHO |
| **TTS Optimizado** | +0.2 FPS | -100ms spikes | ‚≠ê | ‚ùå Pendiente |
| **Adaptive Skip** | Estabiliza | Previene acumulaci√≥n | ‚≠ê | ‚ùå Pendiente |

**Target realista: 19.2 ‚Üí 21-22 FPS** con Async Telemetry (CUDA streams ya aplicado)

---

## üöÄ Plan de Implementaci√≥n

### Fase 1: Async Telemetry (1-2 horas) ‚≠ê √öNICO PENDIENTE CR√çTICO
1. Crear `AsyncTelemetryLogger` class
2. Reemplazar en `main.py`
3. Testing: 5 minutos de ejecuci√≥n continua
4. Validar: No m√°s spikes >100ms despu√©s de warmup

### ~~Fase 2: CUDA Streams~~ ‚úÖ YA IMPLEMENTADO
- Commit 8e4e69a: Multiprocessing con CUDA streams
- CentralWorker usa depth_stream y yolo_stream
- Funcionando en producci√≥n

### Fase 3: TTS Optimizaci√≥n (1 hora) - OPCIONAL
1. Pre-generar WAVs para palabras comunes
2. Fallback a pyttsx3 para frases din√°micas
3. Testing: Validar calidad de audio

---

## üìù Notas

- **Actual:** 19.2 FPS promedio, spikes cada 2-3 segundos de 350-400ms
- **Target:** 21-22 FPS sostenido, sin spikes >100ms
- **Bottleneck principal:** I/O s√≠ncrono (300-400ms cada flush) ‚Üê √öNICO PROBLEMA REAL
- **Quick win:** Async Telemetry elimina el 90% de los spikes
- **Ya optimizado:** ‚úÖ Multiprocessing, ‚úÖ CUDA streams, ‚úÖ TensorRT RGB, ‚úÖ ONNX CUDA depth

---

**Fecha:** 17 Nov 2025  
**Estado:** An√°lisis completado, pendiente implementaci√≥n
