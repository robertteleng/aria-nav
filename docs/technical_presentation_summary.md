# An√°lisis T√©cnico Completo - Sistema de Navegaci√≥n Asistida con Meta Aria

**Proyecto**: Sistema de Navegaci√≥n para Personas con Discapacidad Visual  
**Hardware**: Meta Aria Glasses (RGB + 2xSLAM + IMU + Depth)  
**Autor**: Roberto Rojas Sahuquillo  
**Branch actual**: feature/fase4-tensorrt  

---

## 1. ARQUITECTURA DEL SISTEMA

### Capas de Clean Architecture

El sistema implementa 3 capas claramente separadas:

#### **Capa de Infraestructura** (`src/core/`)
- **Hardware**: `hardware/device_manager.py` - Gesti√≥n de recursos GPU/CPU
- **Observer**: `observer.py` / `mock_observer.py` - Abstracci√≥n del SDK de Aria
- **External**: Wrappers de librer√≠as externas (Aria SDK C++)

#### **Capa de Aplicaci√≥n** (`src/core/`)
- **Vision**: `vision/yolo_processor.py`, `vision/depth_estimator.py`
- **Audio**: `audio/audio_system.py`, `audio/navigation_audio_router.py`
- **Navigation**: `navigation/navigation_pipeline.py`, `navigation/coordinator.py`
- **Telemetry**: `telemetry/telemetry_logger.py`

#### **Capa de Presentaci√≥n** (`src/presentation/`)
- **Dashboards**: `dashboards/opencv_dashboard.py`, `dashboards/rerun_dashboard.py`, `dashboards/web_dashboard.py`
- **Renderers**: Visualizaci√≥n de detecciones y m√©tricas
- **Manager**: `presentation_manager.py` - Orquestaci√≥n de UI

### M√≥dulos Principales y Responsabilidades

| M√≥dulo | Responsabilidad | Tecnolog√≠a |
|--------|----------------|------------|
| **YoloProcessor** | Detecci√≥n de objetos RGB + SLAM | YOLO12n + TensorRT FP16 |
| **DepthEstimator** | Estimaci√≥n de profundidad | Depth-Anything-V2 + ONNX/CUDA |
| **NavigationPipeline** | Orquestaci√≥n del flujo de datos | Threading + multiprocessing |
| **AudioSystem** | S√≠ntesis de voz + beeps espaciales | pyttsx3/say + sounddevice |
| **NavigationAudioRouter** | Cola priorizada de eventos | queue.PriorityQueue + threading |
| **TelemetryLogger** | Logging as√≠ncrono de m√©tricas | asyncio + deque |
| **Observer** | Streaming de frames Aria SDK | DDS (projectaria-tools) |

### Comunicaci√≥n entre Capas

- **Interfaces**: Uso de callbacks y eventos para desacoplamiento
- **Dependency Injection**: Builder pattern en `navigation/builder.py`
- **Event-driven**: Observer pattern para streaming de frames
- **Queue-based**: `multiprocessing.Queue` para IPC entre procesos GPU

---

## 2. PIPELINE DE PROCESAMIENTO COMPLETO

### Flujo de Datos End-to-End

```
Meta Aria Glasses
‚îú‚îÄ‚îÄ RGB Stream (1408x1408, 60 FPS te√≥rico)
‚îú‚îÄ‚îÄ SLAM1 Stream (640x480, 60 FPS)
‚îú‚îÄ‚îÄ SLAM2 Stream (640x480, 60 FPS)
‚îî‚îÄ‚îÄ IMU Data (1000 Hz)

‚Üì Observer (DDS Streaming)
  ‚îú‚îÄ‚îÄ Sincronizaci√≥n multi-c√°mara (timestamp alignment)
  ‚îî‚îÄ‚îÄ Buffer management (7 streams RGB)

‚Üì NavigationPipeline
  ‚îú‚îÄ‚îÄ RGB Detection (YOLO TensorRT 640x640) ‚Üí 40ms
  ‚îú‚îÄ‚îÄ Depth Estimation (ONNX/CUDA 384x384) ‚Üí 27ms
  ‚îú‚îÄ‚îÄ SLAM Detection (YOLO PyTorch 256x256, skip=3) ‚Üí 25ms/frame
  ‚îî‚îÄ‚îÄ IMU Processing (walking/stationary) ‚Üí <1ms

‚Üì NavigationDecisionEngine
  ‚îú‚îÄ‚îÄ Zone Classification (left/center/right)
  ‚îú‚îÄ‚îÄ Distance Estimation (depth hybrid: MiDaS + bbox heuristic)
  ‚îú‚îÄ‚îÄ Priority Ranking (CRITICAL/HIGH/MEDIUM/LOW)
  ‚îî‚îÄ‚îÄ Cooldown Management (per source)

‚Üì AudioRouter (PriorityQueue)
  ‚îú‚îÄ‚îÄ Anti-spam filtering (cooldowns: RGB 1.2s, SLAM 3.0s)
  ‚îú‚îÄ‚îÄ Anti-stutter (duplicate message < 2s)
  ‚îú‚îÄ‚îÄ Grace period (250ms before interrupt)
  ‚îî‚îÄ‚îÄ Telemetry logging

‚Üì AudioSystem
  ‚îú‚îÄ‚îÄ Spatial Beep (100ms, stereo panning)
  ‚îî‚îÄ‚îÄ TTS (say/pyttsx3, ~800ms)

‚Üí Usuario (Audio Output)
```

### Latencias Medidas por Etapa (FASE 4 Final)

| Etapa | Latencia | M√©todo Medici√≥n |
|-------|----------|----------------|
| RGB Capture | ~3ms | `performance.jsonl` timestamp diff |
| YOLO RGB Inference | 40ms | TensorRT FP16, `time.perf_counter()` |
| Depth Inference | 27ms | ONNX CUDA EP, profiled |
| SLAM Inference | 25ms | PyTorch (256x256, cada 3 frames) |
| Decision Engine | 5ms | Python logic, negligible |
| Audio Queueing | <1ms | Priority queue O(log n) |
| **Total Pipeline** | **48ms promedio** | End-to-end telemetry |

### Tecnolog√≠as de Concurrencia

#### Threading (Para I/O-bound)
- `NavigationAudioRouter._run()`: Thread dedicado a procesar cola de audio
- `AsyncTelemetryLogger`: Thread para escritura async de logs
- `AudioSystem.speak_async()`: Thread por cada TTS call

#### Multiprocessing (Para CPU/GPU-bound)
- **Central Worker**: Proceso dedicado RGB + Depth (GPU)
- **SLAM Worker**: Proceso dedicado SLAM1/2 detections (GPU)
- **Main Process**: Streaming + Rendering (CPU-bound)
- **Comunicaci√≥n**: `multiprocessing.Queue` con shared memory

#### Asyncio (Para Network/File I/O)
- `TelemetryLogger.log_*()`: M√©todos async con `deque`
- `ResourceMonitor`: Sampling cada 2s sin bloquear pipeline

---

## 3. ALGORITMO DEPTH HYBRID

### Implementaci√≥n Matem√°tica

El sistema usa **fusi√≥n de dos fuentes**:

1. **MiDaS/Depth-Anything-V2**: Depth map normalizado relativo
2. **Bbox Heuristic**: Estimaci√≥n geom√©trica basada en tama√±o aparente

#### F√≥rmula de Calibraci√≥n Bbox

```python
# Valores de calibraci√≥n emp√≠ricos
FOCAL_LENGTH = 525.0  # pixels (Meta Aria RGB, estimado)
KNOWN_HEIGHT = {
    'person': 1.70,   # metros
    'car': 1.50,
    'chair': 0.90,
    'door': 2.00,
    'table': 0.75
}

# F√≥rmula de distancia:
distance_meters = (KNOWN_HEIGHT[class] * FOCAL_LENGTH) / bbox_height_pixels
```

#### Fusi√≥n Depth Map + Bbox

```python
def estimate_distance_hybrid(depth_map, bbox, class_name):
    # 1. Extraer depth promedio en bbox
    x1, y1, x2, y2 = bbox
    depth_region = depth_map[y1:y2, x1:x2]
    depth_value = np.median(depth_region)  # Robusto a outliers
    
    # 2. Calcular bbox heuristic
    bbox_height = y2 - y1
    bbox_distance = (KNOWN_HEIGHT[class_name] * FOCAL_LENGTH) / bbox_height
    
    # 3. Fusi√≥n ponderada
    # Peso depth_map: 0.7 (m√°s confiable)
    # Peso bbox: 0.3 (calibraci√≥n r√°pida)
    final_distance = 0.7 * depth_value + 0.3 * bbox_distance
    
    return final_distance
```

### Valores de Calibraci√≥n

| Par√°metro | Valor | Fuente |
|-----------|-------|--------|
| **Focal Length RGB** | 525 px | Estimado (no en docs oficiales Aria) |
| **Altura Persona** | 1.70 m | Promedio poblaci√≥n |
| **Altura Coche** | 1.50 m | Est√°ndar sed√°n |
| **Altura Silla** | 0.90 m | Mobiliario com√∫n |
| **Peso Depth Map** | 0.7 | Emp√≠rico (mejor en <3m) |
| **Peso Bbox** | 0.3 | Emp√≠rico (mejor en >5m) |

### Error Medido: ¬±42cm

**Nota**: Este dato **NO se encontr√≥ en el c√≥digo ni logs**. Probablemente fue:
- Medido manualmente con cinta m√©trica en experimentos f√≠sicos
- Calculado en notebooks de an√°lisis no commiteados
- O dato target te√≥rico (no validado a√∫n)

**Recomendaci√≥n**: Documentar expl√≠citamente protocolo de validaci√≥n.

---

## 4. DESARROLLO ITERATIVO - 8 CICLOS

### Evoluci√≥n de Latencias por Fase

| Fase | Fecha | Commits Clave | Latencia | FPS | Cambio Principal |
|------|-------|---------------|----------|-----|------------------|
| **Baseline** | Nov 10 | `04b1e2a` | 320ms | 3.1 | C√≥digo inicial Mac |
| **Pre-FASE 1** | Nov 11 | `14dbfb7` | 283ms | 3.5 | Plan CUDA optimizations |
| **FASE 1** | Nov 12 | `25ba498`, `b914fef` | 150ms | 6.7 | CUDA streams, pinned memory, TF32 |
| **FASE 2 (intento)** | Nov 13 | `8192662`, `01e100e` | 180ms | 5.6 | Multiprocessing (fallido por GIL) |
| **FASE 2 (fix)** | Nov 13 | `a3b8a38` | 95ms | 10.5 | Depth disabled en workers |
| **FASE 3** | - | - | - | - | **SALTADA** (GStreamer innecesario) |
| **FASE 4 (depth CUDA)** | Nov 16 | `4bbd7ce` | 76ms | 13.2 | ONNX Depth con CUDA EP |
| **FASE 4 (final)** | Nov 17 | `8e4e69a` | **48ms** | **18.4** | Multiprocessing re-enabled |

### Gr√°fico de Evoluci√≥n (Texto)

```
Latencia (ms)
320 |‚óè                                   Baseline
    |
250 |  ‚óè                                 Pre-FASE 1
    |
200 |    
    |
150 |      ‚óè                             FASE 1 (CUDA)
    |         ‚óè                          FASE 2 (intento)
100 |           ‚óè                        FASE 2 (fix)
    |              ‚óè                     FASE 4 (depth CUDA)
 50 |                   ‚óè                FASE 4 (final)
    |________________________
     Nov 10  11  12  13  16  17

FPS: 3.1 ‚Üí 3.5 ‚Üí 6.7 ‚Üí 5.6 ‚Üí 10.5 ‚Üí 13.2 ‚Üí 18.4 (+494%)
```

### Cambios T√©cnicos por Ciclo

#### FASE 1: Quick Wins GPU
- **Commits**: `25ba498`, `e959aae`, `b914fef`, `a7c8d5b`
- **Cambios**:
  - YOLO 320‚Üí640, Depth 256‚Üí384 (mayor resoluci√≥n)
  - `torch.backends.cudnn.benchmark = True`
  - `allow_tf32 = True` (RTX 2060 compatible)
  - `pinned_memory=True` para tensores
  - CUDA streams para paralelizar YOLO + Depth
- **Mejora**: 283ms ‚Üí 150ms (-47%)

#### FASE 2: Multiprocessing
- **Commits**: `8192662`, `0017a23`, `01e100e`, `a3b8a38`
- **Problema**: GIL + depth en workers caus√≥ overhead
- **Soluci√≥n**: Depth solo en proceso central, workers solo YOLO
- **Mejora**: 150ms ‚Üí 95ms (-37%)

#### FASE 3: GStreamer (Skipped)
- **Raz√≥n**: Streaming no era bottleneck
- **Alternativa**: Priorizar inferencia (FASE 4)

#### FASE 4: TensorRT
- **Commits**: `e9deceb`, `1906b7e`, `4bbd7ce`, `8e4e69a`
- **Cambios**:
  - YOLO PyTorch ‚Üí TensorRT FP16 (100ms ‚Üí 40ms)
  - Depth PyTorch ‚Üí ONNX/CUDA EP (315ms ‚Üí 27ms)
  - Re-enable multiprocessing con depth optimizado
- **Mejora**: 95ms ‚Üí 48ms (-49%)

---

## 5. M√âTRICAS FINALES DE PERFORMANCE

### Sesi√≥n Analizada: `session_1763392016067`

- **Duraci√≥n**: 70 segundos
- **Frames procesados**: 924 frames
- **Escenario**: Oficina interior (persona + laptop detectados)

### Resultados Globales

| M√©trica | Valor Medido | Objetivo | Estado |
|---------|--------------|----------|--------|
| **FPS Promedio** | 18.4 FPS | ‚â•25 FPS | üü° 74% |
| **Latencia p50** | 45ms | <50ms | ‚úÖ |
| **Latencia p95** | 72ms | <100ms | ‚úÖ |
| **Latencia M√°xima** | 124ms | <200ms | ‚úÖ |
| **Frames <25 FPS** | 32% | <10% | ‚ùå |
| **Frames >200ms** | 0.3% | <5% | ‚úÖ |

### Detecciones

| Clase | Total | Confianza Promedio | Tasa Detecci√≥n |
|-------|-------|-------------------|----------------|
| **person** | 1740 | 0.72 | 188%* |
| **laptop** | 310 | 0.65 | 34% |
| **chair** | 45 | 0.58 | 5% |

*Tasa >100% indica m√∫ltiples personas o detecci√≥n repetida por frame

### An√°lisis de Estabilidad (Ventanas de 50 frames)

| Frames | FPS Avg | Latency Avg | Varianza FPS |
|--------|---------|-------------|--------------|
| 0-50 | 14.2 | 68ms | Alta (warm-up) |
| 50-100 | 18.9 | 51ms | Media |
| 100-150 | 19.3 | 48ms | Baja (estable) |
| 850-900 | 18.1 | 52ms | Baja (sin degradaci√≥n) |

**Observaci√≥n**: No hay memory leak observable (FPS estable despu√©s de warm-up).

### F1-Score de Detecciones

**Nota**: No se encontraron m√©tricas de F1-score/mAP en el c√≥digo ni logs.

**Ground truth ausente**: No hay datasets anotados para validaci√≥n cuantitativa.

**Validaci√≥n realizada**: Cualitativa (observaci√≥n directa de detecciones correctas).

**Recomendaci√≥n**: Crear dataset anotado con 100-200 frames para validaci√≥n formal.

---

## 6. STACK TECNOL√ìGICO COMPLETO

### Hardware

#### Desarrollo (Mac)
- **Modelo**: MacBook Pro M2
- **RAM**: 16 GB
- **GPU**: Apple M2 (10-core, shared memory)
- **Backend**: MPS (Metal Performance Shaders)

#### Producci√≥n Target (NUC)
- **CPU**: Intel NUC11 (i7-1165G7)
- **GPU**: NVIDIA RTX 2060 (6GB VRAM)
- **RAM**: 32 GB DDR4
- **CUDA**: 12.1 (cuda121)
- **cuDNN**: 9.1.0.70

### Software Stack

| Componente | Versi√≥n | Prop√≥sito |
|------------|---------|-----------|
| **Python** | 3.11 | Runtime principal |
| **PyTorch** | 2.5.1+cu121 | Framework ML |
| **CUDA Toolkit** | 12.1 | GPU computing |
| **Ultralytics** | 8.3.228 | YOLO12n inference |
| **TensorRT** | Integrado (via ONNX) | Optimizaci√≥n GPU |
| **ONNX Runtime** | √öltima (deps de torch) | Depth inference |
| **Transformers** | Latest (HF) | Depth-Anything-V2 models |
| **OpenCV** | 4.12.0.88 | Procesamiento imagen |
| **NumPy** | 2.1.2 | Arrays num√©ricos |
| **SoundDevice** | 0.5.3 | Beeps espaciales |
| **pyttsx3** | 2.98 | TTS Linux |
| **Aria SDK** | 2.1.0 (projectaria-tools) | Streaming gafas |
| **Flask-SocketIO** | 5.5.1 | Web dashboard |
| **Rerun-SDK** | 0.22.1 | Dashboard 3D |

### Costos (Estimado)

| Item | Precio |
|------|--------|
| Meta Aria Glasses | $299 |
| Intel NUC11 + RTX 2060 | ~$800 |
| MacBook Pro M2 (desarrollo) | $1299 |
| **Total Hardware** | **~$2400** |
| Software (todo open-source) | $0 |

---

## 7. DECISIONES T√âCNICAS JUSTIFICADAS

### ¬øPor qu√© YOLO12n y no v8/v10?

**Elegido**: YOLO12n (Ultralytics)
- Lanzado Oct 2024 (m√°s reciente)
- +2.3% mAP vs YOLOv11n
- Mejor balance velocidad/precisi√≥n para 640x640
- TensorRT export nativo con `ultralytics`

**Descartados**:
- YOLOv8: Obsoleto (2023)
- YOLOv10: No mejora significativa para edge devices
- YOLOv11: Bueno, pero v12 mejora sin overhead

### ¬øPor qu√© Depth-Anything-V2 y no MiDaS?

**Elegido**: Depth-Anything-V2-Small (HuggingFace)
- mAP superior en datasets indoor
- Modelo m√°s reciente (2024)
- Mejor con objetos peque√±os (<1m¬≤)
- Export ONNX directo

**Descartado**: MiDaS
- M√°s antiguo (2020)
- Menos preciso en indoor
- Usado inicialmente, luego migrado

### ¬øPor qu√© asyncio en TelemetryLogger?

**Elegido**: `asyncio` + `deque`
- I/O-bound (escritura a disco)
- No bloquea pipeline cr√≠tico
- Threading m√°s simple que multiprocessing
- `deque` thread-safe sin locks expl√≠citos

**Descartado**: `multiprocessing`
- Overhead de IPC innecesario para logging
- Complejidad mayor sin beneficio

### ¬øPor qu√© cooldowns RGB 1.2s / SLAM 3.0s?

**Origen**: **Emp√≠rico** (ajuste manual basado en observaci√≥n)

**Rationale**:
- RGB (frontal): Detecciones m√°s cr√≠ticas, cooldown corto
- SLAM (perif√©rico): Menor prioridad, evitar ruido ‚Üí cooldown largo
- Probados manualmente en ~20 sesiones iterativas

**F√≥rmula**: No calculado, valores heur√≠sticos ajustados.

**Valores probados**:
- RGB: 0.5s (muy spam) ‚Üí 1.0s (aceptable) ‚Üí **1.2s** (√≥ptimo)
- SLAM: 2.0s (algo spam) ‚Üí **3.0s** (bien) ‚Üí 4.0s (muy lento)

---

## 8. BLOQUEADORES Y WORKAROUNDS

### WSL2 + Aria SDK

**Problema**: `projectaria-tools` no funciona en WSL2
- Error: DDS networking no puede conectarse a gafas
- USB passthrough no soporta configuraci√≥n compleja de Aria

**Workaround**: Desarrollo dual
- Mac: Testing con gafas reales
- NUC Linux: Testing con `MockObserver` (video replay)

### TensorRT Library Dependencies

**Problema**: `TensorrtExecutionProvider` en ONNX Runtime falla
- Error: `libnvinfer.so.8: cannot open shared object`
- TensorRT libs no en PATH correcto

**Workaround**: Usar solo `CUDAExecutionProvider`
- Performance similar (CUDA EP usa cuDNN optimizado)
- Evita dependency hell de TensorRT

### Memory Leak Monitoring

**Problema**: Sospecha de leak en multiprocessing queues
- FPS degradaba despu√©s de 5+ minutos (en versiones tempranas)

**Soluci√≥n**: `MemoryProfiler` + `ResourceMonitor`
- Snapshot cada 30s
- Detect√≥: no hay leak real (FPS estable en FASE 4)
- Era overhead de warm-up inicial

---

## RESUMEN EJECUTIVO PARA SLIDES

### Tabla de Logros

| Aspecto | Valor Final | Comparaci√≥n |
|---------|-------------|-------------|
| **Latencia Total** | 48ms | -85% vs baseline (320ms) |
| **FPS** | 18.4 | +494% vs baseline (3.1 FPS) |
| **Optimizaciones** | 4 fases | 8 commits cr√≠ticos |
| **Tecnolog√≠as** | 6 core | PyTorch, TensorRT, ONNX, CUDA, MPS |
| **Cobertura FOV** | 180¬∞ | RGB 70¬∞ + SLAM L/R 55¬∞ |
| **Audio Latency** | <100ms | Beep + TTS combinados |
| **Costo Total** | ~$2400 | Hardware completo |

### Diagrama de Arquitectura Sugerido (PlantUML)

```plantuml
@startuml
!theme plain

package "Meta Aria Glasses" {
  [RGB Camera] as RGB
  [SLAM1 Camera] as SLAM1
  [SLAM2 Camera] as SLAM2
  [IMU Sensor] as IMU
}

package "Processing Pipeline" {
  [Observer\n(DDS Streaming)] as OBS
  [Central Worker\n(RGB + Depth)] as CENTRAL
  [SLAM Worker\n(Peripheral)] as SLAMW
  [Decision Engine] as ENGINE
  [Audio Router] as ROUTER
  [Audio System] as AUDIO
}

RGB --> OBS
SLAM1 --> OBS
SLAM2 --> OBS
IMU --> OBS

OBS --> CENTRAL : Queue
OBS --> SLAMW : Queue
CENTRAL --> ENGINE : Results
SLAMW --> ENGINE : Results
ENGINE --> ROUTER : Events
ROUTER --> AUDIO : TTS

note right of CENTRAL
  YOLO TensorRT: 40ms
  Depth ONNX/CUDA: 27ms
end note

note right of ROUTER
  PriorityQueue
  Cooldowns: RGB 1.2s, SLAM 3.0s
  Grace: 250ms
end note

@enduml
```

---

**Documento generado**: 18 Nov 2025  
**Fuentes**: C√≥digo fuente, git history, docs/, logs/, benchmarks/  
**Datos sin c√≥digo**: F1-score, error ¬±42cm (pendiente validaci√≥n formal)
