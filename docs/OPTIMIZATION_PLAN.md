# üöÄ Plan de Optimizaci√≥n de Performance - RTX 2060

**Objetivo**: Alcanzar 60 FPS con m√°xima calidad en RTX 2060  
**Estado Actual**: 13.6 FPS  
**Gap**: 46.4 FPS (340% mejora necesaria)

---

## üìä An√°lisis Actual del Cuello de Botella

### Tiempos Medidos (por frame)
- **Total latencia**: 66.75ms promedio
- **Frames normales**: ~40-45ms (YOLO + rendering)
- **Frames con depth**: ~90-100ms (+50ms depth overhead)

### Identificaci√≥n de Problemas
1. **üêå GIL de Python**: Threading no paralelo real
2. **üì¶ Streaming**: DDS sample lost (CPU->GPU transfer lento)
3. **üîÑ Sincronizaci√≥n**: Todo secuencial, no hay paralelismo
4. **üíæ Memoria**: Copias innecesarias CPU<->GPU

---

## üéØ Plan de Optimizaci√≥n (5 Fases)

### **FASE 1: Quick Wins - GPU Optimization** ‚ö°
**Objetivo**: 20-25 FPS (mejora 50-80%)  
**Esfuerzo**: Bajo (2-3 horas)  
**Riesgo**: Bajo

#### Acciones:
1. **Batch Processing GPU**
   - [ ] Procesar YOLO y Depth en el mismo batch
   - [ ] Mantener frames en GPU (no bajar a CPU)
   - [ ] Usar `torch.cuda.Stream()` para operaciones paralelas
   
2. **Optimizar Transferencias CPU-GPU**
   - [ ] `pinned_memory=True` para tensores
   - [ ] Reducir `.cpu()` innecesarios
   - [ ] Cache de depth map en GPU
   
3. **Aumentar Batch Size**
   - [ ] YOLO procesar 2-3 frames por inferencia
   - [ ] Depth procesar cada 6-9 frames (vs actual 3)

**C√≥digo a modificar:**
- `src/core/vision/yolo_processor.py`
- `src/core/vision/depth_estimator.py`
- `src/core/navigation/navigation_pipeline.py`

---

### **FASE 2: Multiprocessing - Romper el GIL** üîì
**Objetivo**: 35-40 FPS (mejora 170%)  
**Esfuerzo**: Medio (1-2 d√≠as)  
**Riesgo**: Medio (sincronizaci√≥n)

#### Acciones:
1. **Separar en Procesos Independientes**
   ```
   Process 1: Aria Streaming ‚Üí Queue
   Process 2: YOLO Inference (GPU) ‚Üí Queue
   Process 3: Depth Inference (GPU) ‚Üí Queue
   Process 4: Audio + Rendering (CPU)
   ```

2. **Comunicaci√≥n IPC**
   - [ ] `multiprocessing.Queue` con shared memory
   - [ ] Usar `torch.multiprocessing` para GPU sharing
   - [ ] Pipes para sincronizaci√≥n r√°pida

3. **Shared Memory para Frames**
   - [ ] `shared_memory.SharedMemory` para frames grandes
   - [ ] Evitar pickles pesados

**Nuevo dise√±o:**
```python
src/core/processing/
‚îú‚îÄ‚îÄ aria_capture_process.py    # Streaming loop
‚îú‚îÄ‚îÄ yolo_inference_process.py  # GPU YOLO
‚îú‚îÄ‚îÄ depth_inference_process.py # GPU Depth
‚îî‚îÄ‚îÄ coordinator_process.py     # Main orchestrator
```

---

### **FASE 3: GStreamer Pipeline - Zero-Copy** üìπ
**Objetivo**: 50-55 FPS (mejora 270%)  
**Esfuerzo**: Alto (2-3 d√≠as)  
**Riesgo**: Alto (nueva infraestructura)

#### Acciones:
1. **Reemplazar DDS Streaming con GStreamer**
   - [ ] Pipeline directo Aria ‚Üí GPU memory
   - [ ] Hardware decoding (NVDEC)
   - [ ] Zero-copy con `appsink`

2. **GStreamer Pipeline**
   ```bash
   aria_source ! 
   nvvidconv ! 
   video/x-raw(memory:NVMM) ! 
   appsink
   ```

3. **Integraci√≥n con PyTorch**
   - [ ] CuPy para conversi√≥n NVMM ‚Üí Torch tensor
   - [ ] Direct GPU upload sin CPU pass

**Dependencias nuevas:**
- `gstreamer1.0`
- `gstreamer1.0-plugins-bad`
- `python-gi`
- `cupy-cuda11x`

---

### **FASE 4: Model Optimization - TensorRT** üî•
**Objetivo**: 60+ FPS (mejora 340%+)  
**Esfuerzo**: Alto (3-4 d√≠as)  
**Riesgo**: Medio (conversi√≥n de modelos)

#### Acciones:
1. **YOLO a TensorRT**
   - [ ] Exportar YOLO12n a ONNX
   - [ ] Convertir ONNX ‚Üí TensorRT engine
   - [ ] FP16 precision (2x speed vs FP32)
   - [ ] Dynamic shapes para batch variable

2. **Depth Anything V2 a TensorRT**
   - [ ] Exportar modelo HuggingFace ‚Üí ONNX
   - [ ] TensorRT engine con FP16
   - [ ] Fusi√≥n de capas (layer fusion)

3. **Batch Inferencing**
   - [ ] YOLO: batch=4 frames
   - [ ] Depth: batch=2 frames

**Performance esperado:**
- YOLO: 40-45ms ‚Üí **5-8ms** (5-9x faster)
- Depth: 50ms ‚Üí **10-15ms** (3-5x faster)

**Herramientas:**
- `torch2trt`
- `onnx`
- `tensorrt`

---

### **FASE 5: Advanced Optimizations** üéì
**Objetivo**: 60+ FPS sostenido + features adicionales  
**Esfuerzo**: Medio (1-2 d√≠as)  
**Riesgo**: Bajo

#### Acciones:
1. **Frame Skipping Inteligente**
   - [ ] Skip frames basado en motion detection
   - [ ] Interpolaci√≥n de detecciones entre frames
   - [ ] Predictive tracking

2. **GPU Direct RDMA** (si disponible)
   - [ ] Aria ‚Üí GPU sin pasar por CPU RAM
   - [ ] Requiere hardware espec√≠fico

3. **Async Everything**
   - [ ] CUDA streams para overlap
   - [ ] Async audio processing
   - [ ] Non-blocking rendering

4. **Model Quantization**
   - [ ] INT8 inference donde sea posible
   - [ ] Mixed precision (FP16/FP32)

---

## üìã Plan de Ejecuci√≥n Recomendado

### Semana 1: Fundamentos
- **D√≠a 1-2**: FASE 1 (Quick Wins)
- **D√≠a 3-5**: FASE 2 (Multiprocessing)

### Semana 2: Infraestructura
- **D√≠a 1-3**: FASE 3 (GStreamer)
- **D√≠a 4-5**: Testing + ajustes

### Semana 3: Aceleraci√≥n
- **D√≠a 1-4**: FASE 4 (TensorRT)
- **D√≠a 5**: FASE 5 (Advanced)

---

## üîß Configuraci√≥n Hardware √ìptima (RTX 2060)

```python
# Config para RTX 2060 (6GB VRAM)
YOLO_IMAGE_SIZE = 640           # Max resolution
YOLO_BATCH_SIZE = 4             # 4 frames simult√°neos
YOLO_FP16 = True                # Half precision
DEPTH_INPUT_SIZE = 384          # Alta resoluci√≥n
DEPTH_BATCH_SIZE = 2            # 2 frames simult√°neos
DEPTH_FP16 = True               # Half precision

# CUDA optimizations
torch.backends.cudnn.benchmark = True
torch.backends.cuda.matmul.allow_tf32 = True
torch.set_float32_matmul_precision('high')

# Memory management
torch.cuda.empty_cache()        # Peri√≥dicamente
CUDA_VISIBLE_DEVICES = "0"      # Single GPU
```

---

## üìà Mejoras Esperadas por Fase

| Fase | FPS | Mejora | Esfuerzo | Prioridad |
|------|-----|--------|----------|-----------|
| Actual | 13.6 | - | - | - |
| FASE 1 | 22-25 | +65% | Bajo | ‚≠ê‚≠ê‚≠ê |
| FASE 2 | 35-40 | +170% | Medio | ‚≠ê‚≠ê‚≠ê |
| FASE 3 | 50-55 | +270% | Alto | ‚≠ê‚≠ê |
| FASE 4 | 60+ | +340% | Alto | ‚≠ê‚≠ê‚≠ê |
| FASE 5 | 60+ | - | Medio | ‚≠ê |

---

## üö¶ Empezar con FASE 1 - Quick Wins

### Implementaci√≥n Inmediata:

1. **Aumentar resoluciones**
   ```python
   YOLO_IMAGE_SIZE = 640
   DEPTH_INPUT_SIZE = 384
   ```

2. **Optimizar frame skipping**
   ```python
   YOLO_FRAME_SKIP = 0      # Procesar todo
   DEPTH_FRAME_SKIP = 6     # Reducir overhead
   ```

3. **GPU pinned memory**
   ```python
   frame_tensor = torch.from_numpy(frame).cuda(non_blocking=True)
   ```

4. **CUDA streams**
   ```python
   yolo_stream = torch.cuda.Stream()
   depth_stream = torch.cuda.Stream()
   ```

---

## üìù Tracking de Progreso

- [ ] FASE 1: Quick Wins (Target: 22-25 FPS)
- [ ] FASE 2: Multiprocessing (Target: 35-40 FPS)
- [ ] FASE 3: GStreamer (Target: 50-55 FPS)
- [ ] FASE 4: TensorRT (Target: 60+ FPS)
- [ ] FASE 5: Advanced (Target: 60+ FPS sostenido)

---

## üéØ ¬øPor d√≥nde empezamos?

**Recomendaci√≥n**: Empezar con FASE 1 para ganar momentum y validar el approach.

¬øQuieres que implemente FASE 1 ahora? Puedo hacer los cambios en ~30 minutos.
