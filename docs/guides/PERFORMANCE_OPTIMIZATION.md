# ‚ö° Performance Optimization Guide (RTX 2060, Aria Innovation Build)

> Resumen pr√°ctico para sostener 18‚Äì22 FPS con Meta Aria Glasses usando YOLO TensorRT + Depth ONNX. Enfoque de innovaci√≥n (no producto), prioriza reproducibilidad y rapidez de iteraci√≥n.

## üèÉ‚Äç‚ôÇÔ∏è TL;DR
- Objetivo: ~107ms captura‚Üídecisi√≥n, ~150ms con audio; 18‚Äì22 FPS efectivos (YOLO cada 3er frame, Depth cada 12¬∫).
- Hardware: Intel i7 + RTX 2060 (6GB), Ubuntu 22.04, drivers CUDA recientes.
- Modelos: YOLOv11/12n ‚Üí TensorRT FP16 (640x640); Depth-Anything v2 Small ‚Üí ONNX Runtime CUDA (518x518).
- Config cr√≠tica: `YOLO_FRAME_SKIP=3`, `DEPTH_FRAME_SKIP=12`, input 640x640, FP16, cooldown de audio 2s.
- Telemetr√≠a: habilita profiler y logs para verificar latencias por etapa.

## üìä M√©tricas actuales
| M√©trica | Valor | Notas |
|---------|-------|-------|
| FPS efectivo | 18‚Äì22 | YOLO skip 3, Depth skip 12 |
| YOLO latency | ~40ms | TensorRT FP16, batch=1 |
| Depth latency | ~27ms | ONNX CUDA, 518x518 |
| Latencia pipeline (con depth) | ~78ms | Sin TTS |
| Latencia audio (TTS) | ~43ms | pyttsx3 |
| E2E (captura‚Üíaudio) | ~150ms | Con depth |
| VRAM | ~1.5GB / 6GB | ~25% uso |

## ‚úÖ Checklist r√°pido (para reproducir)
1) Exportar YOLO a TensorRT FP16 (input fijo 640x640, workspace 4GB).
2) Exportar Depth-Anything v2 Small a ONNX y ejecutar con CUDA EP.
3) Configurar frame skip: YOLO=3, Depth=12; resoluci√≥n entrada 640x480.
4) Habilitar image enhancement ligero (brillo/contraste) para confianza.
5) Verificar cola de audio: `queue_max_size=3`, `cooldown=2s`.
6) Correr con profiler/telemetr√≠a activada y revisar `performance.jsonl`.

## üîß Knobs de rendimiento (impacto alto)
| Par√°metro | Default | Impacto | Trade-off |
|-----------|---------|---------|-----------|
| `YOLO_FRAME_SKIP` | 3 | FPS‚Üë, latencia‚Üì | Menos frescura visual |
| `DEPTH_FRAME_SKIP` | 12 | FPS‚Üë | Depth menos frecuente |
| Input size YOLO | 640x640 | Latencia‚Üì | Menor precisi√≥n |
| Precision | FP16 | Latencia‚Üì | Ligera p√©rdida de precisi√≥n |
| CUDA Streams | H√≠brido | +0.6 FPS | Ganancia limitada (TRT+ONNX) |
| Audio cooldown | 2s | Evita spam | Menos avisos repetidos |
| Depth resolution | 518x518 | Latencia‚âÉ | Si bajas, depth menos precisa |

## üõ†Ô∏è Recetas clave
- **YOLO ‚Üí TensorRT FP16 (batch=1):** exporta desde PyTorch, fija input 640x640, desactiva dynamic shapes para m√°xima velocidad.
- **Depth ‚Üí ONNX CUDA:** exporta el modelo small; ejecuta con CUDA EP. Reescalar a 518x518 y de vuelta a 480x640.
- **Frame Skip Inteligente:** YOLO cada 3er frame, Depth cada 12¬∫; tracking y fusi√≥n mantienen consistencia entre frames.
- **Fusi√≥n Depth+BBoxes:** calcula media de depth en el bbox, clasifica en close/medium/far y alimenta el Decision Engine.
- **Audio no bloqueante:** cola prioritaria + cooldown 2s; TTS en hilo separado.
- **Telemetry async:** logger con cola `maxsize=2000`, flush en background; evita picos de 250ms por I/O.

## üß™ Validaci√≥n r√°pida
1) Corre el pipeline con telemetr√≠a: revisa `logs/session_*/telemetry/performance.jsonl`.
2) Mide latencia por etapa: YOLO ~40ms, Depth ~27ms, resto ~11ms.
3) FPS: usa `nvidia-smi dmon` y el profiler interno; espera 18‚Äì22 FPS.
4) Audio: confirma que la cola no se desborda (`queue_max_size=3`).

## üêõ Performance troubleshooting
- **FPS <15:** verifica skips (3/12), input size, que se est√© usando TensorRT/ONNX (no PyTorch).
- **CUDA OOM:** reduce depth res (518‚Üí384), desactiva SLAM, limita buffers de detecci√≥n.
- **Audio lag:** revisa cooldown y TTS backend; cola no bloqueante habilitada.
- **Latencia inestable:** profiler on; revisa GC y operaciones I/O en el loop.

## üß≠ Referencias
- Arquitectura consolidada: [`docs/architecture/architecture_document.md`](../architecture/architecture_document.md)
- Historial completo de optimizaciones (archivo): [`docs/archive/cuda/`](../archive/cuda/)

*√öltima actualizaci√≥n: noviembre 2025. Enfoque de innovaci√≥n; ajustar par√°metros seg√∫n experimentaci√≥n.*
